{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMI3yxu2VatPbVigBV60UOF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shuo-Zh/Shuo-Zh.github.io/blob/main/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "kaiming初始化 == xviaer初始化，目的：不为了初次训练时挂掉"
      ],
      "metadata": {
        "id": "H-eB0wclGWwa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pytorch 构建层和块"
      ],
      "metadata": {
        "id": "VGWuPzKc5a07"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "多层感知机"
      ],
      "metadata": {
        "id": "kOE1rRjy6lyw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGhlJRqq2A6l",
        "outputId": "d6e02ac2-1835-40cd-a29f-d68c8b1df957"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0391,  0.0956, -0.2009, -0.0964,  0.0611, -0.1332,  0.0550, -0.0204,\n",
              "         -0.1253,  0.1215],\n",
              "        [ 0.0348,  0.1023, -0.0064, -0.0372, -0.1212, -0.0553, -0.0016,  0.0562,\n",
              "         -0.2344,  0.0408]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# module 任何一个层和神经网络都是 module的子类\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# （单层神经网络）线性层 + relu + 线性层\n",
        "net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10)) #10输出大小\n",
        "# nn.Sequential 定义特殊module\n",
        "X = torch.rand(2, 20) # 2 * 20的随机矩阵；2批量大小；20输入维度；\n",
        "net(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 自定义块"
      ],
      "metadata": {
        "id": "XlSasFY753Dc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "任何一个层都是module子类"
      ],
      "metadata": {
        "id": "EYYdUpcy7cKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):#定义类和参数\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.hidden = nn.Linear(20, 256) # 定义隐藏层\n",
        "    self.out = nn.Linear(256, 10)\n",
        "  def forward(self, X): #定义前向函数\n",
        "    return self.out(F.relu(self.hidden(X))) #nnmodule里F函数，输入到隐藏层 -> 放到输出"
      ],
      "metadata": {
        "id": "9Wqe4lDS7cjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "实例化多层感知机，每次调用正向传播函数时调用这些层"
      ],
      "metadata": {
        "id": "R2SVWJUT8mo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = MLP()\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vYXcoPs8ePM",
        "outputId": "0120c03e-f4b9-4ec0-eb77-1d68ca8dbcc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1791, -0.1161, -0.0796, -0.1858,  0.0697,  0.1372,  0.1101,  0.0149,\n",
              "          0.0276,  0.2784],\n",
              "        [ 0.2524, -0.0433, -0.0547, -0.0918,  0.0016,  0.0500,  0.1110, -0.1143,\n",
              "         -0.0981,  0.2241]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 顺序块 - 方式1（Module子类）"
      ],
      "metadata": {
        "id": "zedi6XDD8uan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 实现 NN- sequential功能\n",
        "class MySequential(nn.Module):\n",
        "    def __init__(self, *args): # *args == list of sequential argument\n",
        "        super().__init__()\n",
        "        # for idx, module in enumerate(args):\n",
        "        #     # 这里，module是Module子类的一个实例。我们把它保存在'Module'类的成员\n",
        "        #     # 变量_modules中。_module的类型是OrderedDict\n",
        "        #     self._modules[str(idx)] = module\n",
        "        for block in args:\n",
        "          self._modules[block] = block\n",
        "\n",
        "    def forward(self, X):\n",
        "        # OrderedDict保证了按照成员添加的顺序遍历它们\n",
        "        for block in self._modules.values():\n",
        "            X = block(X)\n",
        "        return X"
      ],
      "metadata": {
        "id": "T4K34_d98wIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 顺序块 - 方式2"
      ],
      "metadata": {
        "id": "-NgowzX19PyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 实现 NN- sequential功能\n",
        "class MySequential2(nn.Module):\n",
        "    def __init__(self, *args): # *args == list of sequential argument\n",
        "        super().__init__()\n",
        "        for idx, module in enumerate(args):\n",
        "            # 这里，module是Module子类的一个实例。我们把它保存在'Module'类的成员\n",
        "            # 变量_modules中。_module的类型是OrderedDict\n",
        "            self._modules[str(idx)] = module\n",
        "\n",
        "\n",
        "    def forward(self, X):\n",
        "        # OrderedDict保证了按照成员添加的顺序遍历它们\n",
        "        for block in self._modules.values():\n",
        "            X = block(X)\n",
        "        return X"
      ],
      "metadata": {
        "id": "5hoVtGGc9TGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuIYjZDY9e2Q",
        "outputId": "f229d2ae-f191-48c5-ce66-7d800b2066d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1571,  0.1747,  0.1301, -0.1278, -0.2952, -0.1433,  0.0403,  0.0058,\n",
              "          0.1042, -0.0231],\n",
              "        [ 0.1809,  0.2699,  0.0915, -0.1841, -0.4316, -0.1792,  0.0655,  0.0908,\n",
              "          0.1854,  0.0612]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 正向传播函数中执行代码"
      ],
      "metadata": {
        "id": "hdCf2_Ut9f5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FixedHiddenMLP(nn.Module):\n",
        "  ## init和forward中可以做自定义计算\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # 不计算梯度的随机权重参数。因此其在训练期间保持不变\n",
        "        self.rand_weight = torch.rand((20, 20), requires_grad=False) # rand_weight不参与训练，不会计算梯度\n",
        "        self.linear = nn.Linear(20, 20)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = self.linear(X) #先行回归\n",
        "        # 使用创建的常量参数以及relu和mm函数\n",
        "        X = F.relu(torch.mm(X, self.rand_weight) + 1) #手写MM做矩阵乘法\n",
        "        # 复用全连接层。这相当于两个全连接层共享参数\n",
        "        X = self.linear(X)\n",
        "        # 控制流\n",
        "        while X.abs().sum() > 1:\n",
        "            X /= 2\n",
        "        return X.sum()\n",
        "net = FixedHiddenMLP()\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1P4r3Ol-x_d",
        "outputId": "b462b91f-8830-42dd-e435-e743963861c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.0774, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 反向计算自动求导"
      ],
      "metadata": {
        "id": "ZnL1khuk_mNI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#混合搭配各种组合块的方法"
      ],
      "metadata": {
        "id": "Tx97S8F0_p4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NestMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(nn.Linear(20, 64), nn.ReLU(),\n",
        "                                 nn.Linear(64, 32), nn.ReLU())\n",
        "        self.linear = nn.Linear(32, 16)\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.linear(self.net(X))\n",
        "\n",
        "chimera = nn.Sequential(NestMLP(), nn.Linear(16, 20), FixedHiddenMLP())\n",
        "chimera(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkXcOZSC--lt",
        "outputId": "26bda377-92ed-4353-f780-ce930a653b85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.1820, grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#参数管理， 目标是找到使损失函数最小化的模型参数值。"
      ],
      "metadata": {
        "id": "CYXcUtIDAQgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 单隐藏层MLP\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))\n",
        "X = torch.rand(size=(2, 4))\n",
        "net(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqiJkmUpAYKB",
        "outputId": "d339324e-cf67-455d-8e7d-67f81b5ba7e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9516],\n",
              "        [-0.9782]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 参数访问"
      ],
      "metadata": {
        "id": "nxD1lsX_8y2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#拿出权重\n",
        "print(net[2].state_dict()) # 拿出最后的输出层"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdDuvcrdAaTc",
        "outputId": "015c6a38-43d3-4be8-e1ed-6535489b6dc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('weight', tensor([[ 0.3428, -0.2510, -0.2270, -0.1447, -0.3183, -0.1937, -0.3358, -0.0941]])), ('bias', tensor([-0.2711]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#目标参数\n",
        "print(type(net[2].bias)) # Parameter，可以优化参数\n",
        "print(net[2].bias)\n",
        "print(net[2].bias.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBJP3QEDAk-E",
        "outputId": "3c05299a-86d2-4a63-a664-bcc513f15960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.nn.parameter.Parameter'>\n",
            "Parameter containing:\n",
            "tensor([-0.2711], requires_grad=True)\n",
            "tensor([-0.2711])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net[2].weight.grad == None #weight 、grad==梯度"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDtGlzXYA3Fx",
        "outputId": "19a14b44-4672-4416-ede9-17e7172438b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##一次性访问所有参数"
      ],
      "metadata": {
        "id": "cAt0SZhp9dW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#relu没有参数访问不出来"
      ],
      "metadata": {
        "id": "tHGxIHd_9cNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 一次性访问所有参数"
      ],
      "metadata": {
        "id": "yH4RHE5ZBRpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(*[(name, param.shape) for name, param in net[0].named_parameters()])\n",
        "print(*[(name, param.shape) for name, param in net.named_parameters()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlw3Gh6bBD-m",
        "outputId": "8f598286-819a-4010-94a4-853535d7d19f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('weight', torch.Size([8, 4])) ('bias', torch.Size([8]))\n",
            "('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "另一种网络参数访问方式"
      ],
      "metadata": {
        "id": "hpyhmhsgBZu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net.state_dict()['2.bias'].data #根据名字获取参数"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzkhRbAPBT40",
        "outputId": "94561590-25db-4ac3-b1a4-6b1f0c1ad8c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.2711])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 从嵌套块收集参数"
      ],
      "metadata": {
        "id": "ufmRafnxBgO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def block1():\n",
        "    return nn.Sequential(nn.Linear(4, 8), nn.ReLU(),\n",
        "                         nn.Linear(8, 4), nn.ReLU())\n",
        "\n",
        "def block2():\n",
        "    net = nn.Sequential()\n",
        "    for i in range(4):\n",
        "        # 在这里嵌套\n",
        "        net.add_module(f'block {i}', block1()) #add model 可以传字符串\n",
        "    return net\n",
        "\n",
        "rgnet = nn.Sequential(block2(), nn.Linear(4, 1))\n",
        "rgnet(X)"
      ],
      "metadata": {
        "id": "dkxfn93fBdMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9b565e3-629c-43c9-ec36-56d9a5b44954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0648],\n",
              "        [0.0648]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(rgnet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92jimJ_H-NEX",
        "outputId": "ab803c6f-8159-4b18-e54b-986c2da9d0bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Sequential(\n",
            "    (block 0): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (block 1): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (block 2): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "    (block 3): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
            "      (3): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 参数初始化"
      ],
      "metadata": {
        "id": "p3Na4nbNBowE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_normal(m):# init 包含大量初始化函数\n",
        "    if type(m) == nn.Linear:\n",
        "        nn.init.normal_(m.weight, mean=0, std=0.01) #normal下划线在后面，是替换函数\n",
        "        nn.init.zeros_(m.bias)\n",
        "net.apply(init_normal)# apply，所有net里layer，调用函数讲modole作为参数传入\n",
        "net[0].weight.data[0], net[0].bias.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvgoXaNg-1YW",
        "outputId": "bac99d5a-795d-4658-8d55-f331b6c2cdae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0.0031, -0.0109, -0.0017,  0.0010]), tensor(0.))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def init_constant(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        nn.init.constant_(m.weight, 1) #weight，constant为1\n",
        "        nn.init.zeros_(m.bias)\n",
        "net.apply(init_constant)\n",
        "net[0].weight.data[0], net[0].bias.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPwGGTgw-2Ze",
        "outputId": "4d15230d-bd2d-460e-8b68-1aebc046517b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1.]), tensor(0.))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 应用不同的初始化方法"
      ],
      "metadata": {
        "id": "dvNWKlTG_ib6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_xavier(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "def init_42(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        nn.init.constant_(m.weight, 42) #42是宇宙的答案\n",
        "\n",
        "net[0].apply(init_xavier)\n",
        "net[2].apply(init_42)\n",
        "print(net[0].weight.data[0])\n",
        "print(net[2].weight.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SBHZZ4o-3Ir",
        "outputId": "ee860f79-58e3-4179-ece0-e24b74646a54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.2220,  0.2091,  0.0549,  0.1629])\n",
            "tensor([[42., 42., 42., 42., 42., 42., 42., 42.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##自定义初始化"
      ],
      "metadata": {
        "id": "snQSj3aLADtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_init(m):\n",
        "    if type(m) == nn.Linear:\n",
        "        print(\"Init\", *[(name, param.shape)\n",
        "                        for name, param in m.named_parameters()][0])\n",
        "        nn.init.uniform_(m.weight, -10, 10)\n",
        "        m.weight.data *= m.weight.data.abs() >= 5 #保留绝对值大于5的权重\n",
        "\n",
        "net.apply(my_init)\n",
        "net[0].weight[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQ0JcsQs_mnr",
        "outputId": "e2e6f8e6-6818-41ae-e33a-0e410df9788e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Init weight torch.Size([8, 4])\n",
            "Init weight torch.Size([1, 8])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-7.6930, -0.0000,  6.3756,  0.0000],\n",
              "        [-7.7345, -5.6781, -0.0000,  0.0000]], grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##直接设置参数做替换"
      ],
      "metadata": {
        "id": "sTLC4SBYAa5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net[0].weight.data[:] += 1\n",
        "net[0].weight.data[0, 0] = 42\n",
        "net[0].weight.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgrZayPdAGhf",
        "outputId": "9617f7b0-20fb-4293-8a73-3f56dd5f48c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([42.0000,  1.0000,  7.3756,  1.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##参数绑定 - 共享参数"
      ],
      "metadata": {
        "id": "9xpHnI-LAhWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 我们需要给共享层一个名称，以便可以引用它的参数\n",
        "shared = nn.Linear(8, 8)\n",
        "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), #第二个和第三个隐藏层share权重\n",
        "                    shared, nn.ReLU(),\n",
        "                    shared, nn.ReLU(),\n",
        "                    nn.Linear(8, 1))\n",
        "net(X)\n",
        "# 检查参数是否相同\n",
        "print(net[2].weight.data[0] == net[4].weight.data[0])\n",
        "net[2].weight.data[0, 0] = 100\n",
        "# 确保它们实际上是同一个对象，而不只是有相同的值\n",
        "print(net[2].weight.data[0] == net[4].weight.data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F_T_x4EAioX",
        "outputId": "60ec27e3-fb48-4436-f977-bf5cdbc4e7ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([True, True, True, True, True, True, True, True])\n",
            "tensor([True, True, True, True, True, True, True, True])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 自定义层"
      ],
      "metadata": {
        "id": "oMknBPeSBrHG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 构造一个没有任何参数的的层"
      ],
      "metadata": {
        "id": "XRKuYYYqBtra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class CenteredLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, X):\n",
        "        return X - X.mean()\n",
        "\n",
        "layer = CenteredLayer()\n",
        "layer(torch.FloatTensor([1, 2, 3, 4, 5]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BeQNx-dBvx0",
        "outputId": "7eddd7d3-98b1-4b31-a5eb-5e872f916190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2., -1.,  0.,  1.,  2.])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.Sequential(nn.Linear(8, 128), CenteredLayer())\n",
        "Y = net(torch.rand(4, 8))\n",
        "Y.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJ7QNFXlB1KP",
        "outputId": "5902e444-a54c-4ba0-8e81-98534bcd1229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-4.6566e-09, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 带参数的层"
      ],
      "metadata": {
        "id": "BWFvXMgVCIlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLinear(nn.Module):\n",
        "    def __init__(self, in_units, units): # in_units 输入大小与输出大小的矩阵，rand做初始化\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.randn(in_units, units))\n",
        "        self.bias = nn.Parameter(torch.randn(units,))\n",
        "    def forward(self, X):\n",
        "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
        "        return F.relu(linear)"
      ],
      "metadata": {
        "id": "VFWEgcdBCE1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear = MyLinear(5, 3)\n",
        "linear.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVEYQHpjCMXU",
        "outputId": "7b892277-b195-4e8d-b42b-1f5639f7685d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0834,  0.3246, -1.0586],\n",
              "        [ 0.4155,  0.4027, -1.2503],\n",
              "        [ 0.8679,  0.3451,  0.7627],\n",
              "        [-0.3642,  0.8680,  0.7669],\n",
              "        [-2.2921, -2.2194,  0.4480]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))\n",
        "net(torch.rand(2, 64))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEMCNCijCNDR",
        "outputId": "8bad62b5-2905-481e-ff1a-3e8983e9e649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.3961],\n",
              "        [4.0682]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 带参数的图层"
      ],
      "metadata": {
        "id": "EGx5FljaBkdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLinear(nn.Module):\n",
        "    def __init__(self, in_units, units):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.randn(in_units, units)) #nn.parameter包起来\n",
        "        self.bias = nn.Parameter(torch.randn(units,)) # randn做bias\n",
        "    def forward(self, X):\n",
        "        linear = torch.matmul(X, self.weight.data) + self.bias.data #通过.data访问对应参数\n",
        "        return F.relu(linear)"
      ],
      "metadata": {
        "id": "scgOKVooBnvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear = MyLinear(5, 3)\n",
        "linear.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4bRZuYUBzZB",
        "outputId": "38d68eb7-b4d0-4224-96ac-70430e1eb0fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.9320, -0.4483,  3.2404],\n",
              "        [-1.1338, -0.8829,  1.3985],\n",
              "        [ 1.9408, -2.0297,  0.1764],\n",
              "        [ 0.0722,  2.5382, -0.7770],\n",
              "        [-2.2670, -0.8944,  0.4291]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##自定义层执行正向计算"
      ],
      "metadata": {
        "id": "qM3gIQLjCLxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear(torch.rand(2, 5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XG5uRW7MCRTD",
        "outputId": "9a997433-016f-4199-c2bb-7f6bbdfd96b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 1.6445, 1.4613],\n",
              "        [0.0000, 0.3509, 3.6514]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##自定义层构建模型"
      ],
      "metadata": {
        "id": "Ntl9f05HCgjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))\n",
        "net(torch.rand(2, 64))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kM17c_eBCdNh",
        "outputId": "491ae320-a2bf-42eb-b6d8-19d39556a4e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.],\n",
              "        [0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#读写文件"
      ],
      "metadata": {
        "id": "piz7lNEzCoV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "x = torch.arange(4)\n",
        "torch.save(x, 'x-file')"
      ],
      "metadata": {
        "id": "0HFza5hDCpih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x2 = torch.load('x-file')\n",
        "x2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Dv40FDeC-BZ",
        "outputId": "49465aca-2a10-4351-b0bd-ce7cf3c23b75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 加载和保存模型参数"
      ],
      "metadata": {
        "id": "sAeCmetXDCW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 不能存储模型定义，torchScript可以存模型定义，存权重即可\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.hidden = nn.Linear(20, 256)\n",
        "        self.output = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.output(F.relu(self.hidden(x)))\n",
        "\n",
        "net = MLP()\n",
        "X = torch.randn(size=(2, 20))\n",
        "Y = net(X)"
      ],
      "metadata": {
        "id": "7rsveFlWC-_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(net.state_dict(), 'mlp.params')"
      ],
      "metadata": {
        "id": "-N1OmepSDFVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load回来模型"
      ],
      "metadata": {
        "id": "vbDnhm19ExkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clone = MLP()\n",
        "clone.load_state_dict(torch.load(\"mlp.params\"))\n",
        "clone.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjbRuBJZElzk",
        "outputId": "329e5bc6-cc9c-465a-9f9b-0645c0612745"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
              "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_clone = clone(X)\n",
        "Y_clone = Y"
      ],
      "metadata": {
        "id": "iQE4JFICE1AO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "czLTxmW_GVip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT 定义网络"
      ],
      "metadata": {
        "id": "99EFeGScFCxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 简单神经网络\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# 定义一个简单的两层神经网络\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim) # 输入层到隐藏层的线性变换\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim) # 隐藏层到输出层的线性变换\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x)) # 对隐藏层使用ReLU激活函数\n",
        "        x = self.fc2(x) # 输出层不需要激活函数\n",
        "        return x\n",
        "\n",
        "# 定义神经网络的输入、隐藏和输出层的维度\n",
        "input_dim = 10\n",
        "hidden_dim = 20\n",
        "output_dim = 5\n",
        "\n",
        "# 实例化神经网络\n",
        "net = SimpleNet(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "# 定义一个输入张量\n",
        "input_tensor = torch.randn(1, input_dim)\n",
        "\n",
        "# 向前传播\n",
        "output_tensor = net(input_tensor)\n",
        "\n",
        "print(output_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1ZAzE8GFF0N",
        "outputId": "1c7dcd31-748d-42a1-b2ca-6658b7cd80ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0180, -0.4689, -0.0553, -0.0474,  0.2244]],\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 加载数据集\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# 划分数据集\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 定义一个简单的两层神经网络\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# 定义神经网络的输入、隐藏和输出层的维度\n",
        "input_dim = X.shape[1]\n",
        "hidden_dim = 20\n",
        "output_dim = len(set(y))\n",
        "\n",
        "# 实例化神经网络\n",
        "net = SimpleNet(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "# 定义损失函数和优化器\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
        "\n",
        "# 训练神经网络\n",
        "for epoch in range(100):\n",
        "    # 将数据转换为张量\n",
        "    inputs = torch.tensor(X_train, dtype=torch.float32)\n",
        "    labels = torch.tensor(y_train, dtype=torch.long)\n",
        "\n",
        "    # 将梯度清零\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 向前传播\n",
        "    outputs = net(inputs)\n",
        "\n",
        "    # 计算损失函数\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # 反向传播和优化\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# 在测试集上评估模型的准确性\n",
        "inputs = torch.tensor(X_test, dtype=torch.float32)\n",
        "labels = torch.tensor(y_test, dtype=torch.long)\n",
        "outputs = net(inputs)\n",
        "_, predicted = torch.max(outputs.data, 1)\n",
        "accuracy = accuracy_score(predicted, labels)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xbNre0QCPh7",
        "outputId": "b2c2ceab-8dc5-45c7-eab7-79bc3d3de5c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 加载数据集\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# 划分数据集\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 定义一个简单的两层神经网络\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# 定义神经网络的输入、隐藏和输出层的维度\n",
        "input_dim = X.shape[1]\n",
        "hidden_dim = 50\n",
        "output_dim = len(set(y))\n",
        "\n",
        "# 实例化神经网络\n",
        "net = SimpleNet(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "# 定义损失函数和优化器\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "# 训练神经网络\n",
        "for epoch in range(500):\n",
        "    # 将数据转换为张量\n",
        "    inputs = torch.tensor(X_train, dtype=torch.float32)\n",
        "    labels = torch.tensor(y_train, dtype=torch.long)\n",
        "\n",
        "    # 将梯度清零\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 向前传播\n",
        "    outputs = net(inputs)\n",
        "\n",
        "    # 计算损失函数\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # 反向传播和优化\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 每50个周期输出一次信息\n",
        "    if epoch % 50 == 0:\n",
        "        # 在测试集上评估模型的准确性\n",
        "        inputs = torch.tensor(X_test, dtype=torch.float32)\n",
        "        labels = torch.tensor(y_test, dtype=torch.long)\n",
        "        outputs = net(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        accuracy = accuracy_score(predicted, labels)\n",
        "        print(f\"Epoch [{epoch+1}/500], Loss: {loss.item():.4f}, Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# 在测试集上评估模型的准确性\n",
        "inputs = torch.tensor(X_test, dtype=torch.float32)\n",
        "labels = torch.tensor(y_test, dtype=torch.long)\n",
        "outputs = net(inputs)\n",
        "_, predicted = torch.max(outputs.data, 1)\n",
        "accuracy = accuracy_score(predicted, labels)\n",
        "print(\"Final Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mb7AKXBIfN3",
        "outputId": "f83dea80-5d9d-4ab8-d175-3f3f6c2678de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/500], Loss: 1.3591, Test Accuracy: 0.3667\n",
            "Epoch [51/500], Loss: 0.7286, Test Accuracy: 0.8333\n",
            "Epoch [101/500], Loss: 0.5287, Test Accuracy: 0.9000\n",
            "Epoch [151/500], Loss: 0.4193, Test Accuracy: 0.9333\n",
            "Epoch [201/500], Loss: 0.3449, Test Accuracy: 1.0000\n",
            "Epoch [251/500], Loss: 0.2863, Test Accuracy: 1.0000\n",
            "Epoch [301/500], Loss: 0.2383, Test Accuracy: 1.0000\n",
            "Epoch [351/500], Loss: 0.1995, Test Accuracy: 1.0000\n",
            "Epoch [401/500], Loss: 0.1692, Test Accuracy: 1.0000\n",
            "Epoch [451/500], Loss: 0.1459, Test Accuracy: 1.0000\n",
            "Final Test Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "隐藏层神经元数量增加到50，使用了Adam优化器，并将学习率设置为0.001。我们还将训练周期数增加到了500，并且在每50个周期输出一次信息，包括训练集上的损失函数和测试集上的准确性。最后，我们在测试集上评估了模型的准确性，并将结果输出。"
      ],
      "metadata": {
        "id": "X9DGvHpVOXuv"
      }
    }
  ]
}